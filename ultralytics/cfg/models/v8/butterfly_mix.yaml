# ----------------------
# Custom Backbone
# ----------------------
nc: 3
backbone:
  - [-1, 1, DWSConv, [32, 3, 2]]        # 0: stem (640 -> 320) , 32
  - [-1, 1, DWSConv, [64, 3, 2]]        # 1: 320 -> 160 , 64
  - [-1, 1, DenseBlock, [64, 3, 16]]    # 2: 160 -> 160 , 64
  - [-1, 1, CBAM, [64]]                 # 3: 160 -> 160, 64, C3
  - [-1, 1, DWSConv, [128, 3, 2]]       # 4: 160 -> 80, 128
  - [-1, 1, DWSConv, [256, 3, 2]]      # 5: 80 -> 40, 256
  - [-1, 1, DenseBlock, [256, 4, 24]]   # 6: 40 -> 40 , 256
  - [-1, 1, CBAM, [256]]                # 7: 40 -> 40, 256, C4
  - [-1, 1, DWSConv, [512, 3, 2]]       # 8: 40 -> 20, 512
  - [-1, 1, DWSConv, [1024, 3, 2]]       # 9: 20 -> 10, 1024
  - [-1, 1, CBAM, [1024]]               # 10: 10 -> 10, 1024, C5

# ----------------------
# Neck + Head (Standard FPN)
# ----------------------
head :
    # -- Step 1: Feature adaptors with better attention --
  - [3, 1, Conv, [128, 1, 1]]     #11: P3
  - [11, 1, TripletAttention, [128]]  #12: More advanced than SE/CBAM
  - [7, 1, Conv, [128, 1, 1]]     #13: P4
  - [13, 1, TripletAttention, [128]] #14
  - [10, 1, Conv, [128, 1, 1]]     #15: P5
  - [15, 1, TripletAttention, [128]]  #16
  
  # -- Step 2: Top-down fusion --
  - [16, 1, nn.Upsample, [None, 2, "nearest"]] #17
  - [[17, 14], 1, GatedFusion, [128]]      #18: modulated fusion
  - [18, 1, Conv, [128, 3, 1]]  #19
  
  - [19, 1, nn.Upsample, [None, 2, "nearest"]]  #20
  - [[10, 12], 1, GatedFusion, [128]]  #21
  - [21, 1, Conv, [128, 3, 1]]  #22

  - [[22, 19, 16], 1, Detect, [nc]] #23

